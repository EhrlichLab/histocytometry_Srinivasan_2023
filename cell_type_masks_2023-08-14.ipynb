{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary gate for cell types\n",
    "\n",
    "How should I establish the binary gate? What should I use for the threshold? I could just tinker with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Mesmer_pypi conda environment\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import re\n",
    "from deco import synchronized, concurrent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_adaptive_binary_gate(img_arr, median_kernel_size= 21, adaptive_subtraction= 0, adaptive_kernel_size= 21, morphology_kernel = (15,15)):\n",
    "    num_channels = np.shape(img_arr)[0] \n",
    "    ## tifffile loads in ch x h x w\n",
    "\n",
    "    threshold_list = [None] * (num_channels -1)\n",
    "        ## Removing DAPI from morphological masks b/c not used for this segmentation\n",
    "\n",
    "    for i in range(1, num_channels):\n",
    "        slice = img_arr[i,...]\n",
    "        \n",
    "        ## OpenCV documentation recommended blurring prior to adaptive thresholding\n",
    "        blurred = cv2.medianBlur(slice, median_kernel_size)\n",
    "\n",
    "        threshold_img = cv2.adaptiveThreshold(blurred, \n",
    "                                              255, \n",
    "                                              cv2.ADAPTIVE_THRESH_GAUSSIAN_C, ## I think Gaussian looks significantly better than mean for cortical images.\n",
    "                                              cv2.THRESH_BINARY, \n",
    "                                              adaptive_kernel_size, \n",
    "                                              adaptive_subtraction)\n",
    "        \n",
    "        ## Morphological operation to remove noise\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morphology_kernel)\n",
    "        morphology_img = cv2.morphologyEx(threshold_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        ## Adding channel dimension for concatenation \n",
    "        threshold_list[i-1] = morphology_img[np.newaxis, ...]\n",
    "\n",
    "    adaptive_binary_img = np.concatenate(threshold_list)\n",
    "    return(adaptive_binary_img)\n",
    "\n",
    "\n",
    "def make_cell_type_mask(adaptive_binary_img, cell_type):\n",
    "    img_shape = np.shape(adaptive_binary_img)[1:3]\n",
    "    mask = np.zeros(img_shape)\n",
    "\n",
    "    ## Channel gates assume that channel order matches directory names in /stor/scratch/Ehrlich/Users/John/histocytometry/raw_images \n",
    "        ## See also /stor/work/Ehrlich/Users/John/projects/misc/histocytometry/scripts/scyan_iterative_pipeline.py \n",
    "        ## No DAPI channel for gates \n",
    "    if cell_type == \"aDC2_Sirpa\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [255,0,255]) | np.all(pixel_val == [255,255,255])\n",
    "    elif cell_type == \"cDC2\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [0,255,255])\n",
    "    elif cell_type == \"aDC1\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [255,0,255]) | np.all(pixel_val == [255,255,255])\n",
    "    elif cell_type == \"aDC2_XCR1\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [0,255,255])\n",
    "    elif cell_type == \"macrophage\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [255,255,255]) ## CD63+, but lowish\n",
    "    elif cell_type == \"monoDC2\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [255,255,255])\n",
    "    elif cell_type == \"pDC\":\n",
    "        for row in range(img_shape[0]):\n",
    "            for col in range(img_shape[1]):\n",
    "                pixel_val = adaptive_binary_img[:, row, col]\n",
    "                mask[row, col] = np.all(pixel_val == [255, 0, 255]) | np.all(pixel_val == [255,255,255])\n",
    "    else: \n",
    "        raise ValueError(\"Cell type: \" + cell_type + \" doesn't match hardcoded options\")\n",
    "    \n",
    "    return(mask)    \n",
    "\n",
    "def np_table(arr):\n",
    "    ## Making this to get some summary stats on the images conveniently\n",
    "    unique_values, counts = np.unique(arr, return_counts=True)\n",
    "    np_table = pd.DataFrame({\"unique_values\" : unique_values,\n",
    "                            \"counts\" : counts})\n",
    "    return(np_table)\n",
    "    \n",
    "\n",
    "@concurrent\n",
    "def gate_thymus_histocytometry(img_dir, img_name, cell_type, median_kernel_size= 21, save_mask= False, downsample_length= 0):\n",
    "    ## I should think about doing kwargs for make_adaptive_binary_img parameters.\n",
    "\n",
    "    ## Making individual marker binary gates and saving them for later reference. \n",
    "    img_arr = tifffile.imread(os.path.join(img_dir, img_name))\n",
    "    if downsample_length > 0:\n",
    "        img_arr = img_arr[:,0:downsample_length, 0:downsample_length]\n",
    "    adaptive_binary_img = make_adaptive_binary_gate(img_arr, median_kernel_size= median_kernel_size)\n",
    "    \n",
    "    if save_mask:\n",
    "        out_path = os.path.join(img_dir, \"individual_gates_on_image.ome.tif\")\n",
    "        overlaid_mask = np.concatenate((img_arr, adaptive_binary_img))\n",
    "        tifffile.imwrite(out_path, overlaid_mask)\n",
    "    print(\"Done with adaptive thresholding!\")\n",
    "\n",
    "    ## Making cell type mask using combined binary mask input \n",
    "    cell_type_mask = make_cell_type_mask(adaptive_binary_img, cell_type)\n",
    "    cell_type_mask = cell_type_mask * 255\n",
    "        ## Converting 0 and 1 to more dynamic color range.\n",
    "    cell_type_mask = cell_type_mask.astype(\"uint8\")\n",
    "    print(\"Done with cell type mask!\")\n",
    "\n",
    "    print(np_table(cell_type_mask))\n",
    "\n",
    "    ## Blocking this out for now. I'm not sure this is how I'm going to do it. \n",
    "    # ## Make cell type directory for easier use with MCQuant later.\n",
    "    # out_path = os.path.join(img_dir, \"cell_type_\" + cell_type)\n",
    "    # if not os.path.exists(out_path):\n",
    "    #     os.mkdir(out_path)\n",
    "\n",
    "    if save_mask:\n",
    "        tifffile.imwrite(os.path.join(img_dir, cell_type + \"_mask.tif\"), cell_type_mask)\n",
    "        cell_type_on_img = np.concatenate((img_arr, cell_type_mask[np.newaxis, ...]))\n",
    "        tifffile.imwrite(os.path.join(img_dir, cell_type + \"_on_image.ome.tif\"), cell_type_on_img)   \n",
    "    print(\"Done with cell type mask!\")\n",
    "\n",
    "        ## I'll run this through MCquant to get the cell count and area \n",
    "        ## I can use the area to filter out garbage \"cells\" and count easier than doing it by hand. \n",
    "            ## There may be an easier way to do this with FIJI.\n",
    "\n",
    "\n",
    "@synchronized\n",
    "def parallelize_cell_type_gating(img_dirs, cell_type, save_mask, downsample_length= 0):\n",
    "    ## Do I want to do thresholding for this? I'm not sure how to implement that. \n",
    "    for img_dir in img_dirs:\n",
    "        gate_thymus_histocytometry(\n",
    "            img_dir            = img_dir, \n",
    "            img_name           = \"reordered_image.ome.tif\", \n",
    "            cell_type          = cell_type, \n",
    "            median_kernel_size = 21,  ## 31\n",
    "            save_mask          = save_mask,\n",
    "            downsample_length  = downsample_length\n",
    "        )\n",
    "\n",
    "@concurrent\n",
    "def pixel_counts(img_dir, cell_type_mask_name, medullary_mask_name, cortical_mask_name, out_name) -> None:\n",
    "    ## Load in data \n",
    "    cell_type_mask = os.path.join(img_dir, cell_type_mask_name)\n",
    "    medullary_mask = os.path.join(img_dir, medullary_mask_name)\n",
    "    cortical_mask  = os.path.join(img_dir, cortical_mask_name)\n",
    "\n",
    "    ## Find tissue cells \n",
    "    medullary_cells = cell_type_mask[medullary_mask]\n",
    "    cortical_cells  = cell_type_mask[cortical_mask]\n",
    "\n",
    "    ## Which pixels are cell type-specific \n",
    "    medullary_cell_pixels = medullary_cells > 0 \n",
    "    cortical_cell_pixels = cortical_cells  > 0 \n",
    "    \n",
    "    ## Size of the tissue region\n",
    "    medulla_pixel_size = medullary_cells.size\n",
    "    cortex_pixel_size  = cortical_cells.size\n",
    "\n",
    "    cortex_medulla_ratio = cortex_pixel_size/medulla_pixel_size\n",
    "\n",
    "    cell_df = pd.DataFrame({\n",
    "        \"img_dir\"               : img_dir, \n",
    "        \"cell_type\"             : cell_type_mask_name,\n",
    "        \"medullary_cell_pixels\" : medullary_cell_pixels, \n",
    "        \"cortical_cell_pixels\"  : cortical_cell_pixels, \n",
    "        \"medulla_pixel_size\"    : medulla_pixel_size,\n",
    "        \"cortex_pixel_size\"     : cortex_pixel_size,\n",
    "        \"cortex_medulla_ratio\"  : cortex_medulla_ratio\n",
    "    })\n",
    "\n",
    "    cell_df.to_csv(os.path.join(img_dir, out_name),index= False)\n",
    "    \n",
    "    return None\n",
    "\n",
    "@synchronized\n",
    "def parallelize_pixel_counts(img_dirs, cell_type) -> None:\n",
    "    for img_dir in img_dirs: \n",
    "        pixel_counts(\n",
    "            img_dir             = img_dir, \n",
    "            cell_type_mask_name = cell_type + \"_on_image.ome.tif\",\n",
    "            medullary_mask_name = \"medulla_mask.tif\", \n",
    "            cortical_mask_name  = \"cortex_mask.tif\",\n",
    "            out_name            = cell_type + \"_pixel_counts.csv\" \n",
    "        )\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir  = \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "img_dirs = [os.path.join(raw_dir, my_dir) for my_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", my_dir)]\n",
    "img_dirs.sort()\n",
    "\n",
    "DAPI_CD63_CD11c_Sirpa_dirs    = [img_dir for img_dir in img_dirs if re.search(\"DAPI_CD63_CD11c_Sirpa\",   img_dir)]\n",
    "DAPI_CD63_CD11c_XCR1_dirs     = [img_dir for img_dir in img_dirs if re.search(\"DAPI_CD63_CD11c_XCR1\",    img_dir)]\n",
    "DAPI_Sirpa_CD63_MerTK_dirs    = [img_dir for img_dir in img_dirs if re.search(\"DAPI_Sirpa_CD63_MerTK\",   img_dir)]\n",
    "DAPI_Sirpa_CD11c_CD14_dirs    = [img_dir for img_dir in img_dirs if re.search(\"DAPI_Sirpa_CD11c_CD14\",   img_dir)]\n",
    "DAPI_B220_CD11c_SiglecH_dirs  = [img_dir for img_dir in img_dirs if re.search(\"DAPI_B220_CD11c_SiglecH\", img_dir)]\n",
    "\n",
    "img_dict = {\n",
    "    \"aDC2_Sirpa\" : DAPI_CD63_CD11c_Sirpa_dirs,\n",
    "    \"cDC2\"       : DAPI_CD63_CD11c_Sirpa_dirs,\n",
    "    \"aDC1\" :  DAPI_CD63_CD11c_XCR1_dirs,\n",
    "    \"aDC2_XCR1\" : DAPI_CD63_CD11c_XCR1_dirs, \n",
    "    \"macrophage\" : DAPI_Sirpa_CD63_MerTK_dirs,\n",
    "    \"monoDC2\" :DAPI_Sirpa_CD11c_CD14_dirs, \n",
    "    \"pDC\" : DAPI_B220_CD11c_SiglecH_dirs\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with adaptive thresholding!\n",
      "Done with adaptive thresholding!\n",
      "Done with adaptive thresholding!\n",
      "Done with adaptive thresholding!\n",
      "Done with cell type mask!\n",
      "   unique_values     counts\n",
      "0              0  135938279\n",
      "1            255    3413145\n",
      "Done with cell type mask!\n"
     ]
    }
   ],
   "source": [
    "parallelize_cell_type_gating(\n",
    "    img_dirs          = DAPI_CD63_CD11c_Sirpa_dirs, \n",
    "    cell_type         = \"aDC2_Sirpa\",\n",
    "    save_mask         = True,\n",
    "    downsample_length = 0\n",
    ")\n",
    "\n",
    "## This might be worth moving to a script and scripting everything. (If it owrks.) \n",
    "\n",
    "## I am running a full image dataset to try to see how that works for the parallelize_pixel_counts(). \n",
    "\n",
    "## Any image with two cell types gets run twice with the way I've currently written it. \n",
    "\n",
    "## I should look at the images and decide if I want to do a morphology manipulation to get the actual DCs. \n",
    "## I could think about blurring the initial images with something like a median blur. \n",
    "\n",
    "\n",
    "## What about instead of quantifying the number of actual cells, I just count the number of trip positive pixels? \n",
    "    ## I almost prefer that methodology. It's so much simpler. \n",
    "    ## This would look like saving a mask for the cell type, segmenting that mask into medulla and cortex. \n",
    "    ## Counting the positive pixels, then plotting the positive pixels. \n",
    "    ## Is it a valid assumption that a vast majority of cell type pixels will be part of a real cell? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize_pixel_counts(\n",
    "    img_dirs = DAPI_CD63_CD11c_Sirpa_dirs,\n",
    "    cell_type = \"aDC2_Sirpa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize_cell_type_gating(\n",
    "    img_dirs          = DAPI_CD63_CD11c_Sirpa_dirs, \n",
    "    cell_type         = \"cDC2\",\n",
    "    save_mask         = True,\n",
    "    downsample_length = 7_500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in img_dict.keys():\n",
    "    parallelize_pixel_counts(\n",
    "        img_dirs  = img_dict[key], \n",
    "        cell_type = key \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize_cell_type_gating(\n",
    "    img_dirs  = DAPI_CD63_CD11c_XCR1_dirs,\n",
    "    cell_type = \"aDC1\",\n",
    "    save_mask = True\n",
    ")\n",
    "\n",
    "parallelize_cell_type_gating(\n",
    "    img_dirs  = DAPI_CD63_CD11c_XCR1_dirs,\n",
    "    cell_type = \"aDC2_XCR1\",\n",
    "    save_mask = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize_cell_type_gating(\n",
    "    img_dirs  = DAPI_Sirpa_CD63_MerTK_dirs,\n",
    "    cell_type = \"macrophage\",\n",
    "    save_mask = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize_cell_type_gating(\n",
    "    img_dirs  = DAPI_Sirpa_CD11c_CD14_dirs,\n",
    "    cell_type = \"monoDC2\",\n",
    "    save_mask = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize_cell_type_gating(\n",
    "    img_dirs  = DAPI_B220_CD11c_SiglecH_dirs,\n",
    "    cell_type = \"pDC\",\n",
    "    save_mask = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mesmer_pypi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
