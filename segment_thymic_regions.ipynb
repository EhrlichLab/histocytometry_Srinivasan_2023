{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating initial thymic region segmentation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import typing\n",
    "str_or_path = typing.Union[str, os.PathLike]\n",
    "from deco import synchronized, concurrent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tif(img_dir, image_to_remove= \"image.tif\") -> None:\n",
    "    img_path = [os.path.join(img_dir, img_file) for img_file in os.listdir(img_dir) if re.search(image_to_remove, img_file) and not img_file.startswith(\".\")]\n",
    "    assert len(img_path)  == 1, f\"More than one file to remove in {img_dir}\"\n",
    "    img_path = img_path[0]\n",
    "    os.remove(img_path)\n",
    "    return None\n",
    "    \n",
    "def setup_image(image_dir, glob_str= \"image.tif\", channel_loc= 2, median_ksize= 11, mean_ksize = (11,11), normalize= False):\n",
    "    image_name = [file_path for file_path in Path(image_dir).rglob(glob_str)]\n",
    "    if len(image_name) > 1:\n",
    "        print(image_dir + \" has more than one tif\")\n",
    "    full_img  = tifffile.imread(os.path.join(image_dir, *image_name))\n",
    "    img = full_img[channel_loc, ...]\n",
    "    \n",
    "    if normalize: \n",
    "        ## Normalize imaging data\n",
    "        scaled_img = (img - np.mean(img)) / np.std(img)\n",
    "        norm_img = np.arcsinh(scaled_img)\n",
    "        norm_img = norm_img.astype(\"uint8\")\n",
    "        ## Median blur\n",
    "        med_blur = cv2.medianBlur(norm_img, median_ksize)  \n",
    "    else: \n",
    "        ## Median blur\n",
    "        med_blur = cv2.medianBlur(img, median_ksize)  \n",
    "\n",
    "    ## Adding a mean blur instead to get an even blurry medulla. \n",
    "    mean_ksize = (11,11)\n",
    "    mean_blur = cv2.blur(med_blur, mean_ksize)\n",
    "\n",
    "    return mean_blur\n",
    "\n",
    "def run_image_GMM(img, n_gaussians= 4, downsample_divisor= 4):\n",
    "    ## Downsampling to decrease computation time\n",
    "    reshaped_img = img.reshape((img.size, 1)).flatten()\n",
    "\n",
    "    ## Removing the outliers to deal w/ some bright medulla that might've caused some issues. \n",
    "        ## I thought about filtering the bottom outliers, but the values are always going to be 0. \n",
    "    top_outliers = np.percentile(reshaped_img, [97.5])\n",
    "    reshaped_img = reshaped_img[(reshaped_img < top_outliers)]\n",
    "    downsampled_img = np.random.choice(a       = reshaped_img, \n",
    "                                       size    = reshaped_img.size // downsample_divisor, \n",
    "                                       replace = False)\n",
    "\n",
    "    ## Add dimension for use w/ GMM\n",
    "    downsampled_img= downsampled_img[..., np.newaxis]\n",
    "    gm = GaussianMixture(n_components= n_gaussians)\n",
    "    gm.fit(downsampled_img)\n",
    "        ## This is the step that takes a while \n",
    "\n",
    "    thresholds = gm.means_.flatten()\n",
    "    thresholds.sort()\n",
    "\n",
    "    return thresholds\n",
    "\n",
    "\n",
    "@concurrent\n",
    "def GMM_wrapper(img, n):\n",
    "    ## Making this wrapper to add deco concurrency to GMM function\n",
    "    model = GaussianMixture(n_components= n).fit(img)\n",
    "    return model\n",
    "\n",
    "\n",
    "@synchronized # And we add this for the function which calls the concurrent function\n",
    "def parallelize_GMMs(img, max_components):\n",
    "    models = [GMM_wrapper(img= img, n= n) for n in np.arange(2, max_components+1)]\n",
    "    return(models)\n",
    "\n",
    "\n",
    "def find_n_gaussians(img, max_components):\n",
    "    downsampled_img= np.random.choice(a        = img.reshape((img.size, 1)).flatten(), \n",
    "                                      size     = img.size // 4, \n",
    "                                      replace  = False)\n",
    "\n",
    "    GMM_models = parallelize_GMMs(img= downsampled_img, max_components= max_components)\n",
    "\n",
    "    n_components = np.arange(2, max_components)\n",
    "    plt.plot(n_components, [m.bic(downsampled_img) for m in GMM_models], label='BIC')\n",
    "    plt.plot(n_components, [m.aic(downsampled_img) for m in GMM_models], label='AIC')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('n_components')\n",
    "\n",
    "\n",
    "def make_threshold_masks(img, sorted_thresholds, morph_ksize= (75, 75), morph_median_ksize= 251):\n",
    "\n",
    "    num_thresholds = sorted_thresholds.size\n",
    "\n",
    "    threshold_masks = np.zeros((num_thresholds, img.shape[0], img.shape[1]))\n",
    "\n",
    "    for i in range(0, num_thresholds):\n",
    "        threshold  = sorted_thresholds[i]\n",
    "        binary_img = img > threshold\n",
    "        binary_img = binary_img * np.uint8(1)     \n",
    "\n",
    "        ## Generate tissue shapes \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morph_ksize)\n",
    "        binary_img = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        ## Remove salt-and-pepper noise\n",
    "        binary_img = cv2.medianBlur(binary_img, morph_median_ksize)\n",
    "\n",
    "        ## Removing small islands\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_img)\n",
    "\n",
    "        min_spot_area = 50_000\n",
    "        filtered_img = np.zeros_like(binary_img)\n",
    "        for label in range(1, num_labels):\n",
    "            area = stats[label, cv2.CC_STAT_AREA]\n",
    "            if area >= min_spot_area:\n",
    "                filtered_img[labels == label] = 255\n",
    "\n",
    "        ## Filling small holes\n",
    "        contour, hier = cv2.findContours(filtered_img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_hole_area= 250_000\n",
    "\n",
    "        for cnt in contour:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area <= max_hole_area:\n",
    "                cv2.drawContours(filtered_img,[cnt],0,255,-1)\n",
    "\n",
    "        threshold_masks[i,...] = filtered_img\n",
    "    return threshold_masks\n",
    "\n",
    "def overlay_cortex_and_medulla(image_dir, medulla, cortex, out_name= \"tissue_segmented_image.ome.tif\", image_name= \"reordered_image.ome.tif\") -> None:\n",
    "    medulla = medulla[np.newaxis,...]\n",
    "    cortex  = cortex[np.newaxis,...]\n",
    "\n",
    "    all_channels_img = tifffile.imread(os.path.join(image_dir, image_name))\n",
    "    tissue_img = np.concatenate((all_channels_img, cortex, medulla))\n",
    "    tifffile.imwrite(os.path.join(image_dir, out_name), tissue_img)\n",
    "    return None \n",
    "\n",
    "@concurrent\n",
    "def histocytometry_wrapper(image_dir, whole_lobe_threshold_rank, medullary_threshold_rank, save_masks= True, plot_thresholds= True, plot_tissues= True, setup_kwargs= {}, run_image_GMM_kwargs= {}, make_threshold_masks_kwargs= {}):\n",
    "    print(\"Starting segmentation of \" + image_dir + \"\\n\")\n",
    "    \n",
    "    img = setup_image(image_dir = image_dir, **setup_kwargs)\n",
    "\n",
    "    sorted_thresholds = run_image_GMM(img= img, **run_image_GMM_kwargs)\n",
    "\n",
    "    threshold_masks = make_threshold_masks(img= img, sorted_thresholds= sorted_thresholds, **make_threshold_masks_kwargs)\n",
    "    threshold_masks = threshold_masks.astype(\"uint8\") \n",
    "        ## Hard-coding, but I could replace with img.dtype\n",
    "\n",
    "    medulla_mask = threshold_masks[medullary_threshold_rank-1,...]\n",
    "    whole_lobe_mask = threshold_masks[whole_lobe_threshold_rank-1,...]\n",
    "    cortex_mask = whole_lobe_mask - medulla_mask\n",
    "\n",
    "    if plot_tissues:\n",
    "        _, ax = plt.subplots(1,4)\n",
    "        ax[0].imshow(img)\n",
    "        ax[0].set_title('Marker')\n",
    "        ax[1].imshow(whole_lobe_mask, cmap= plt.cm.gray)\n",
    "        ax[1].set_title('Whole lobe')\n",
    "        ax[2].imshow(medulla_mask, cmap= plt.cm.gray)\n",
    "        ax[2].set_title('Medulla')\n",
    "        ax[3].imshow(cortex_mask, cmap= plt.cm.gray)\n",
    "        ax[3].set_title(\"Cortex\")\n",
    "        plt.suptitle(image_dir) \n",
    "        plt.show()\n",
    "\n",
    "    if \"n_gaussians\" in list(run_image_GMM_kwargs.keys()):\n",
    "        n_gaussians= run_image_GMM_kwargs[\"n_gaussians\"]\n",
    "    else:\n",
    "        n_gaussians= 4\n",
    "\n",
    "    if plot_thresholds:\n",
    "        _, ax = plt.subplots(1,n_gaussians)\n",
    "        for i in range(0, n_gaussians):\n",
    "            ax[i].imshow(threshold_masks[i,...], cmap= plt.cm.gray)\n",
    "            ax[i].set_title(f'Gaussian {i+1}')\n",
    "            ax[i].axison= False\n",
    "        plt.suptitle(image_dir) \n",
    "        plt.show() \n",
    "\n",
    "\n",
    "    if save_masks:\n",
    "        tifffile.imwrite(os.path.join(image_dir, \"medulla_mask.tif\"), medulla_mask)\n",
    "        tifffile.imwrite(os.path.join(image_dir, \"cortex_mask.tif\"),  cortex_mask)  \n",
    "\n",
    "        overlay_cortex_and_medulla(image_dir = image_dir, \n",
    "                                   medulla   = medulla_mask, \n",
    "                                   cortex    = cortex_mask)\n",
    "\n",
    "\n",
    "@synchronized\n",
    "def histocytometry_wrapper_parallelization(image_dirs, whole_lobe_threshold_rank, medullary_threshold_rank, n_gaussians= 4, save_masks= True, plot_tissues= False, plot_thresholds= True):\n",
    "    for image_dir in image_dirs:\n",
    "        histocytometry_wrapper(\n",
    "            image_dir                 = image_dir, \n",
    "            setup_kwargs              = {\"glob_str\" : \"reordered_image.ome.tif\"}, \n",
    "            save_masks                = save_masks, \n",
    "            run_image_GMM_kwargs      = {\"n_gaussians\" : n_gaussians}, \n",
    "            plot_tissues              = plot_tissues,  \n",
    "            plot_thresholds           = plot_thresholds, \n",
    "            whole_lobe_threshold_rank = whole_lobe_threshold_rank,\n",
    "            medullary_threshold_rank  = medullary_threshold_rank)\n",
    "    return None\n",
    "\n",
    "\n",
    "def tissue_segmentation_plot(img_dir, img, thresholds, threshold_masks):\n",
    "    print(\"Starting plot\")\n",
    "    _, ax = plt.subplots(1,len(thresholds)+1, figsize= (12,6))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Marker\")\n",
    "    for i in range(1, len(thresholds)+1):\n",
    "        ax[i].imshow(threshold_masks[i-1,...], cmap= plt.cm.gray)\n",
    "        ax[i].set_title(f'Thresh: {round(thresholds[i-1], 1)}')\n",
    "    plt.suptitle(img_dir) \n",
    "    plt.show() \n",
    "\n",
    "@concurrent\n",
    "def tissue_segmentation(img_dir, thresholds, morph_ksize, channel_loc, out_name= \"\", glob_str= \"reordered_image.ome.tif\", save_mask= False, normalize= False) -> None:\n",
    "    print(\"Starting \" + img_dir + \"\\n\")\n",
    "\n",
    "    ## Take stain and apply thresholds\n",
    "    img = setup_image(image_dir= img_dir, glob_str= glob_str,  channel_loc= channel_loc, normalize= normalize)\n",
    "    threshold_masks = make_threshold_masks(img= img, sorted_thresholds= thresholds, morph_ksize= morph_ksize)\n",
    "    threshold_masks = threshold_masks.astype(\"uint8\") \n",
    "\n",
    "    tissue_segmentation_plot(\n",
    "        img_dir         = img_dir, \n",
    "        img             = img,\n",
    "        thresholds      = thresholds, \n",
    "        threshold_masks = threshold_masks\n",
    "    )\n",
    "\n",
    "    if save_mask:\n",
    "        assert min(threshold_masks.shape) == 1, \"There are multiple threshold masks. Make sure there is only one threshold in the thresholds argument.\"\n",
    "        tifffile.imwrite(os.path.join(img_dir, out_name), threshold_masks.squeeze())\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "@synchronized\n",
    "def parallelize_segmentation(img_dirs, thresholds, morph_ksize, channel_loc, save_mask, out_name= \"\", glob_str= \"reordered_image.ome.tif\", normalize= False):\n",
    "    ## Use this function to speed up plotting of whole lobe masks and medulla masks\n",
    "    ## I'll visually inspect the results to pick the best thresholds\n",
    "    for img_dir in img_dirs:\n",
    "        tissue_segmentation(img_dir     = img_dir, \n",
    "                            thresholds  = thresholds, \n",
    "                            channel_loc = channel_loc, \n",
    "                            glob_str    = glob_str,\n",
    "                            save_mask   = save_mask,\n",
    "                            out_name    = out_name,\n",
    "                            normalize   = normalize,\n",
    "                            morph_ksize = morph_ksize)\n",
    "        \n",
    "\n",
    "@concurrent\n",
    "def medulla_gmm_wrapper(img_dir, medullary_threshold_rank= 4, glob_str= \"reordered_image.ome.tif\", channel_loc= 2, downsample_divisor= 8, n_gaussians= 4, save_mask= False, out_name= \"medulla_mask.tif\", normalize= False) -> None:\n",
    "    ## Take CD11c or CD63 stains \n",
    "    medulla_stain = setup_image(image_dir= img_dir, glob_str= glob_str,  channel_loc= channel_loc, normalize= normalize)\n",
    "    \n",
    "    ## Run various GMMs\n",
    "    sorted_thresholds = run_image_GMM(img= medulla_stain, n_gaussians= n_gaussians, downsample_divisor= downsample_divisor)\n",
    "\n",
    "    threshold_masks = make_threshold_masks(img= medulla_stain, sorted_thresholds= sorted_thresholds)\n",
    "    threshold_masks = threshold_masks.astype(\"uint8\") \n",
    "\n",
    "    tissue_segmentation_plot(\n",
    "        img_dir         = img_dir, \n",
    "        img             = medulla_stain,\n",
    "        thresholds      = sorted_thresholds, \n",
    "        threshold_masks = threshold_masks\n",
    "    )\n",
    "\n",
    "    medulla_mask= threshold_masks[medullary_threshold_rank-1,...]\n",
    "\n",
    "    if save_mask:\n",
    "        tifffile.imwrite(os.path.join(img_dir, out_name), medulla_mask)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "@synchronized\n",
    "def parallelize_medulla(img_dirs, medullary_threshold_rank, save_mask= False, channel_loc= 2, n_gaussians= 4, normalize= False):\n",
    "    for img_dir in img_dirs: \n",
    "        medulla_gmm_wrapper(\n",
    "            img_dir                  = img_dir, \n",
    "            save_mask                = save_mask,\n",
    "            channel_loc              = channel_loc, \n",
    "            medullary_threshold_rank = medullary_threshold_rank,\n",
    "            n_gaussians              = n_gaussians,\n",
    "            normalize                = normalize\n",
    "        )\n",
    "\n",
    "def make_cortex(img_dir, medulla_mask= \"medulla_mask.tif\", whole_lobe_mask= \"whole_lobe_mask.tif\") -> None:\n",
    "\n",
    "    medulla_mask = tifffile.imread(os.path.join(img_dir, medulla_mask))\n",
    "    whole_lobe_mask = tifffile.imread(os.path.join(img_dir, whole_lobe_mask))\n",
    "    cortex_mask = whole_lobe_mask - medulla_mask\n",
    "    cortex_mask = cortex_mask.astype(\"uint8\") \n",
    "    \n",
    "    tifffile.imwrite(os.path.join(img_dir, \"cortex_mask.tif\"), cortex_mask)\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulling out the cleaned Medulla masks \n",
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "img_dirs = [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", img_dir) and not re.search(\"_Sirpa_C$\", img_dir)]\n",
    "img_dirs.sort()\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    img_w_medulla = tifffile.imread(os.path.join(img_dir, \"img_w_medulla.ome.tif\"))\n",
    "    medulla_mask  = img_w_medulla[4,...]\n",
    "    binary_medulla_mask = medulla_mask > 0 \n",
    "\n",
    "    # plt.imshow(binary_medulla_mask)\n",
    "    \n",
    "    tifffile.imwrite(os.path.join(img_dir, \"cleaned_medulla_mask.tif\"), binary_medulla_mask)\n",
    "    print(f\"Done with {img_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cortex and medulla cortex\n",
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "img_dirs = [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", img_dir) and not re.search(\"Sirpa_C$\", img_dir)]\n",
    "img_dirs.sort()\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir)\n",
    "    img= tifffile.imread(os.path.join(img_dir, \"reordered_image.ome.tif\"))\n",
    "    whole_lobe_mask = tifffile.imread(os.path.join(img_dir, \"whole_lobe_mask.tif\")).astype(\"uint8\")\n",
    "    ## Convert my poorly formatted whole lobe mask to 0 and 1 instead of 0 and 255\n",
    "    whole_lobe_mask = whole_lobe_mask > 0\n",
    "    cleaned_medulla_mask = tifffile.imread(os.path.join(img_dir, \"cleaned_medulla_mask.tif\")).astype(\"uint8\")\n",
    "\n",
    "    cortex_mask = whole_lobe_mask - cleaned_medulla_mask\n",
    "\n",
    "    medulla        = img * cleaned_medulla_mask \n",
    "    cortex         = img * cortex_mask\n",
    "\n",
    "    tifffile.imwrite(os.path.join(img_dir, \"cleaned_medulla_img.ome.tif\"), medulla)\n",
    "    tifffile.imwrite(os.path.join(img_dir, \"cleaned_cortex_img.ome.tif\"), cortex)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole lobe segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "img_dirs = [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", img_dir)]\n",
    "img_dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is what I used to generate the whole_lobe_mask.tif\n",
    "## I followed this up with some manual filling of holes and removing artifacts.  \n",
    "if True:\n",
    "    raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "    img_dirs = [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", img_dir)]\n",
    "    img_dirs.sort()\n",
    "\n",
    "    thresholds = np.arange(13,14)\n",
    "\n",
    "    parallelize_segmentation(\n",
    "        img_dirs    = img_dirs, \n",
    "        thresholds  = thresholds, \n",
    "        channel_loc = 0, ## DAPI\n",
    "        glob_str    = \"reordered_image.ome.tif\",\n",
    "        save_mask   = True,\n",
    "        out_name    = \"whole_lobe_mask.tif\",\n",
    "        morph_ksize = (201, 201) \n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medullary segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "img_dirs= [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", img_dir)]\n",
    "M3_dirs= [\"20x_pan_DAPI_CD207_CD11c_XCR1_C\", \"20x_pan_DAPI_CD207_CD11c_XCR1_D\", \"20x_pan_DAPI_B220_CD11c_SiglecH_C\", \"20x_pan_DAPI_CD63_CD11c_Sirpa_B\"]\n",
    "CD14_dirs = [img_dir for img_dir in os.listdir(raw_dir) if re.search(\"CD14_[A-D]$\", img_dir)]\n",
    "CD14_dirs.sort()\n",
    "M4_dirs = [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]\", img_dir) and img_dir not in M3_dirs and img_dir not in CD14_dirs]\n",
    "M4_dirs.sort()\n",
    "\n",
    "CD14_dirs = [os.path.join(raw_dir, img_dir) for img_dir in CD14_dirs]\n",
    "M3_dirs= [os.path.join(raw_dir, img_dir) for img_dir in M3_dirs]\n",
    "\n",
    "img_dict = {\n",
    "    \"M4\" : M4_dirs,\n",
    "    \"M3\" : M3_dirs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "\n",
    "## Using the third gaussian \n",
    "assigned_M3_dirs = [\"CD63_CD11c_Sirpa_A\",  \n",
    "                    \"B220_CD11c_SiglecH_A\",\n",
    "                    \"Sirpa_CD11c_CD14_B\", \n",
    "                    \"B220_CD11c_SiglecH_C\"] \n",
    "M3_dirs = [os.path.join(raw_dir, \"20x_pan_DAPI_\" + img_dir) for img_dir in assigned_M3_dirs]\n",
    "M3_dirs.sort()\n",
    "\n",
    "for img_dir in M3_dirs:\n",
    "    print(img_dir)\n",
    "    \n",
    "parallelize_medulla(\n",
    "    img_dirs                 = M3_dirs, \n",
    "    medullary_threshold_rank = 3, \n",
    "    save_mask                = True, \n",
    "    channel_loc              = 2, \n",
    "    n_gaussians              = 4, \n",
    "    normalize                = False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "\n",
    "## Using the fourth gaussian\n",
    "assigned_M4_dirs = [\"B220_CD11c_SiglecH_B\", \"B220_CD11c_SiglecH_C\", \n",
    "                    \"CD207_CD11c_XCR1_A\", \"CD207_CD11c_XCR1_B\", \"CD207_CD11c_XCR1_C\", \"CD207_CD11c_XCR1_D\",\n",
    "                    \"CD63_CD11c_XCR1_A\", \"CD63_CD11c_XCR1_B\", \"CD63_CD11c_XCR1_C\", \"CD63_CD11c_XCR1_D\",\n",
    "                    \"CD63_CD11c_Sirpa_B\", \"CD63_CD11c_Sirpa_D\",\n",
    "                    \"Sirpa_CD63_MerTK_A\", \"Sirpa_CD63_MerTK_B\", \"Sirpa_CD63_MerTK_C\", \"Sirpa_CD63_MerTK_D\",\n",
    "                    \"Sirpa_CD11c_CD14_A\", \"Sirpa_CD11c_CD14_C\"]\n",
    "M4_dirs = [os.path.join(raw_dir, \"20x_pan_DAPI_\" + img_dir) for img_dir in assigned_M4_dirs]\n",
    "M4_dirs.sort()\n",
    "\n",
    "for img_dir in M4_dirs:\n",
    "    print(img_dir)\n",
    "\n",
    "parallelize_medulla(\n",
    "    img_dirs                 = M4_dirs, \n",
    "    medullary_threshold_rank = 4, \n",
    "    save_mask                = True, \n",
    "    channel_loc              = 2, \n",
    "    n_gaussians              = 4, \n",
    "    normalize                = False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir= \"/stor/scratch/Ehrlich/Users/John/histocytometry/raw_images/images_2023-08-10\"\n",
    "img_dirs = [os.path.join(raw_dir, img_dir) for img_dir in os.listdir(raw_dir) if re.search(\"_[A-D]$\", img_dir) and not re.search(\"Sirpa_C$\", img_dir)]\n",
    "img_dirs.sort()\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir)\n",
    "\n",
    "out_name = \"img_w_medulla.ome.tif\"\n",
    "for img_dir in img_dirs:\n",
    "    medulla= tifffile.imread(os.path.join(img_dir, \"medulla_mask.tif\"))\n",
    "    medulla = medulla[np.newaxis,...]\n",
    "    img    = tifffile.imread(os.path.join(img_dir, \"reordered_image.ome.tif\"))\n",
    "\n",
    "    img_w_medulla= np.concatenate((img, medulla))\n",
    "    tifffile.imwrite(os.path.join(img_dir, out_name), img_w_medulla)\n",
    "    print(f\"Done with {img_dir}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making cortex out of medulla and whole lobe masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dir in img_dirs:\n",
    "    make_cortex(img_dir, medulla_mask= \"medulla_mask.tif\", whole_lobe_mask= \"whole_lobe_mask.tif\")\n",
    "    print(f\"Done with {img_dir}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay tissue masks on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dir in img_dirs:\n",
    "    medulla_mask = tifffile.imread(os.path.join(img_dir, \"medulla_mask.tif\"))\n",
    "    cortex_mask  = tifffile.imread(os.path.join(img_dir, \"cortex_mask.tif\"))\n",
    "\n",
    "    overlay_cortex_and_medulla(\n",
    "        image_dir  = img_dir,\n",
    "        medulla    = medulla_mask, \n",
    "        cortex     = cortex_mask, \n",
    "        out_name   = \"tissue_segmented_image.ome.tif\", \n",
    "        image_name = \"reordered_image.ome.tif\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## I wonder if I'm overfitting for my training image. \n",
    "## This really is crazy slow. I should think about writing this in julia or with cython as well as using a gamma model instead. \n",
    "\n",
    "## The parallelization messes up the print statements. There is probably a way to hold the prints until everything is done on one image, but I don't want to mess with that.\n",
    "\n",
    "## I need to go through the images and decide which ones look good and which ones look bad. \n",
    "## Several images have what really looks like clear batch effects from the tiles. \n",
    "## The biggest issues with the images are the technical issues. \n",
    "    ## I'll have to go through and manually remove the bright spots. (I have to document which ones have blacked out regions.)\n",
    "## I think picking the medulla and cortex images will have to be done manually. \n",
    "\n",
    "## Why didn't any of the images get printed? I think this was a one off jupyter issue, but I removed the image figure size to see if that did anything. \n",
    "## I don't think this was the issue, but it worked after that. \n",
    "\n",
    "## After this run, I'll try it with five gaussians. \n",
    "\n",
    "## I need to break this apart into images that are using medullary or cortical for each gaussian. \n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mesmer_pypi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
